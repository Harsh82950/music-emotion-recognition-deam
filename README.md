# music-emotion-recognition-deam
CNN-based music emotion recognition system using mel spectrograms and the DEAM dataset, implemented in PyTorch.
This is a compact README that recruiters actually read in 30â€“40 seconds.
You can replace your current README with this, or keep it as a shorter version.

ğŸµ Music Emotion Recognition (DEAM Dataset)
ğŸ” Overview

A CNN-based Music Emotion Recognition system that predicts continuous valence and arousal values from music audio using mel spectrograms and PyTorch.

âš™ï¸ Approach

Extracted mel spectrograms from audio using Librosa

Built a custom PyTorch Dataset & DataLoader

Designed a CNN regression model for emotion prediction

Trained and evaluated the model on the DEAM dataset using MSE loss

ğŸ§  Model

Input: Mel spectrogram (128 Ã— time)

Architecture: 3 Conv blocks + regression head

Output: Valence & Arousal

ğŸ› ï¸ Tech Stack

Python Â· PyTorch Â· Librosa Â· NumPy Â· Pandas

â–¶ï¸ Run
python -m src.train
python -m src.evaluate

ğŸ¯ Use Cases

Music recommendation Â· Mood detection Â· Affective computing
